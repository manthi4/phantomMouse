{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "express-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import pyautogui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-easter",
   "metadata": {},
   "source": [
    "## Go to model card, here for details:\n",
    "https://google.github.io/mediapipe/solutions/models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "future-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'C:/Users/suman/Downloads/hand_landmark_full.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hundred-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "noble-final",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "distinct-remove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1 224 224   3]\n"
     ]
    }
   ],
   "source": [
    "# Test the model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "print(input_shape)\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "typical-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "twenty-catalyst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.10708542e+02 1.78701111e+02 9.36002107e-05 1.16525246e+02\n",
      "  1.55639862e+02 7.67216015e+00 1.22199120e+02 1.30634430e+02\n",
      "  9.94702339e+00 1.21300224e+02 1.11144073e+02 1.03095951e+01\n",
      "  1.18885399e+02 9.52503662e+01 1.13462238e+01 1.16304886e+02\n",
      "  1.05075401e+02 1.60085754e+01 1.14657585e+02 7.79017181e+01\n",
      "  1.76496620e+01 1.16808105e+02 6.20959625e+01 1.74722805e+01\n",
      "  1.19863037e+02 5.51077728e+01 1.78024101e+01 1.14302246e+02\n",
      "  1.05211052e+02 1.21598454e+01 1.19409729e+02 7.36728287e+01\n",
      "  1.32218924e+01 1.19018234e+02 5.80808220e+01 1.22761984e+01\n",
      "  1.19659821e+02 4.86031036e+01 1.22752762e+01 1.11268036e+02\n",
      "  1.07103569e+02 8.13047218e+00 1.20892929e+02 7.67701721e+01\n",
      "  9.04858780e+00 1.21320282e+02 6.48137512e+01 1.01739302e+01\n",
      "  1.25831596e+02 5.42307434e+01 1.16294289e+01 1.12972267e+02\n",
      "  1.11313950e+02 4.61103153e+00 1.21751549e+02 8.67613220e+01\n",
      "  8.32156849e+00 1.23665619e+02 7.47534027e+01 1.13709154e+01\n",
      "  1.26023262e+02 6.57088776e+01 1.33023834e+01]]\n"
     ]
    }
   ],
   "source": [
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-pantyhose",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/lite/api_docs/python/tf/lite/Interpreter#get_output_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "amazing-reggae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identity\n",
      "  165\n",
      "  <class 'numpy.float32'>\n",
      "  [ 1 63]\n",
      "Identity_1\n",
      "  164\n",
      "  <class 'numpy.float32'>\n",
      "  [1 1]\n",
      "Identity_2\n",
      "  162\n",
      "  <class 'numpy.float32'>\n",
      "  [1 1]\n",
      "Identity_3\n",
      "  166\n",
      "  <class 'numpy.float32'>\n",
      "  [ 1 63]\n"
     ]
    }
   ],
   "source": [
    "print(output_details[0]['name'])\n",
    "print(\" \",output_details[0]['index'])\n",
    "print(\" \",output_details[0]['dtype'])\n",
    "print(\" \",output_details[0]['shape'])\n",
    "\n",
    "print(output_details[1]['name'])\n",
    "print(\" \",output_details[1]['index'])\n",
    "print(\" \",output_details[1]['dtype'])\n",
    "print(\" \",output_details[1]['shape'])\n",
    "\n",
    "print(output_details[2]['name'])\n",
    "print(\" \",output_details[2]['index'])\n",
    "print(\" \",output_details[2]['dtype'])\n",
    "print(\" \",output_details[2]['shape'])\n",
    "\n",
    "print(output_details[3]['name'])\n",
    "print(\" \",output_details[3]['index'])\n",
    "print(\" \",output_details[3]['dtype'])\n",
    "print(\" \",output_details[3]['shape'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "connected-intellectual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.10708542e+02, 1.78701111e+02, 9.36002107e-05, 1.16525246e+02,\n",
       "        1.55639862e+02, 7.67216015e+00, 1.22199120e+02, 1.30634430e+02,\n",
       "        9.94702339e+00, 1.21300224e+02, 1.11144073e+02, 1.03095951e+01,\n",
       "        1.18885399e+02, 9.52503662e+01, 1.13462238e+01, 1.16304886e+02,\n",
       "        1.05075401e+02, 1.60085754e+01, 1.14657585e+02, 7.79017181e+01,\n",
       "        1.76496620e+01, 1.16808105e+02, 6.20959625e+01, 1.74722805e+01,\n",
       "        1.19863037e+02, 5.51077728e+01, 1.78024101e+01, 1.14302246e+02,\n",
       "        1.05211052e+02, 1.21598454e+01, 1.19409729e+02, 7.36728287e+01,\n",
       "        1.32218924e+01, 1.19018234e+02, 5.80808220e+01, 1.22761984e+01,\n",
       "        1.19659821e+02, 4.86031036e+01, 1.22752762e+01, 1.11268036e+02,\n",
       "        1.07103569e+02, 8.13047218e+00, 1.20892929e+02, 7.67701721e+01,\n",
       "        9.04858780e+00, 1.21320282e+02, 6.48137512e+01, 1.01739302e+01,\n",
       "        1.25831596e+02, 5.42307434e+01, 1.16294289e+01, 1.12972267e+02,\n",
       "        1.11313950e+02, 4.61103153e+00, 1.21751549e+02, 8.67613220e+01,\n",
       "        8.32156849e+00, 1.23665619e+02, 7.47534027e+01, 1.13709154e+01,\n",
       "        1.26023262e+02, 6.57088776e+01, 1.33023834e+01]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data_0 = interpreter.get_tensor(output_details[0]['index'])\n",
    "output_data_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "affecting-murder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00860468]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data_1 = interpreter.get_tensor(output_details[1]['index'])\n",
    "output_data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "foreign-routine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46441147]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data_2 = interpreter.get_tensor(output_details[2]['index'])\n",
    "output_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "champion-giving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.02237508e-03,  7.67518282e-02,  3.87248024e-02,\n",
       "         1.25506073e-02,  5.78480661e-02,  4.18520570e-02,\n",
       "         1.77433491e-02,  3.29556763e-02,  3.49037945e-02,\n",
       "         1.16502158e-02,  7.98656046e-03,  2.14334242e-02,\n",
       "         9.38664377e-03, -1.61155462e-02,  9.96954739e-03,\n",
       "         5.36477566e-03, -4.24903631e-03,  9.01447237e-03,\n",
       "         1.66255236e-03, -2.65102386e-02, -2.27767229e-03,\n",
       "         3.33292037e-03, -4.16475385e-02,  3.23686004e-03,\n",
       "         1.79009140e-03, -5.67043871e-02,  3.42591107e-03,\n",
       "        -4.84221429e-03, -2.76446342e-03,  2.31543928e-03,\n",
       "        -2.18552351e-03, -4.30181026e-02, -6.63595647e-03,\n",
       "        -3.81018221e-03, -6.07405901e-02, -4.40052152e-03,\n",
       "        -8.72820616e-03, -7.98309445e-02, -2.89678574e-05,\n",
       "        -5.26937097e-03, -2.56948173e-04, -7.49412924e-03,\n",
       "        -2.66161561e-03, -3.40172052e-02, -1.30470395e-02,\n",
       "         3.02687287e-03, -5.22272140e-02, -4.03909385e-03,\n",
       "         4.28539515e-03, -6.41643554e-02,  1.09213442e-02,\n",
       "        -6.91697001e-03,  1.44165605e-02, -4.63570654e-03,\n",
       "        -1.33993104e-03, -8.66210461e-03, -9.06772912e-03,\n",
       "        -9.22165811e-04, -3.40377726e-02,  5.94601035e-04,\n",
       "         3.34808230e-03, -4.90360484e-02,  1.34197026e-02]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data_3 = interpreter.get_tensor(output_details[3]['index'])\n",
    "output_data_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "necessary-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# You can setup your camera settings\n",
    "cap.set(3,1920)\n",
    "cap.set(4,1080)\n",
    "\n",
    "cv2.namedWindow('image')\n",
    "# cv2.createTrackbar('a','image',0,255,nothing)\n",
    "while cap.isOpened():\n",
    "    re, frame = cap.read()\n",
    "    # convert the image to RGB\n",
    "    image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "        # flip the image\n",
    "    image = cv2.flip(image,1)\n",
    "    \n",
    "    image.flags.writeable = False\n",
    "    output_data_0, output_data_1, output_data_2, output_data_3 = process_frame(image)\n",
    "    \n",
    "    image.flags.writeable = True\n",
    "    cv2.putText(image, f'output_data_1 {output_data_1}', (20,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (300, 50, 50), 2)\n",
    "    cv2.putText(image, f'output_data_2 {output_data_2}', (20,80), cv2.FONT_HERSHEY_SIMPLEX, 1, (300, 50, 50), 2)\n",
    "    \n",
    "    cv2.imshow('image',image)\n",
    "\n",
    "#     print(output_data_1,\" \", output_data_1)\n",
    "    if cv2.waitKey(10) & 0xff == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afraid-player",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "editorial-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizer = tf.image.resize(\n",
    "#     images, size, method=ResizeMethod.BILINEAR, preserve_aspect_ratio=False,\n",
    "#     antialias=False, name=None\n",
    "# )\n",
    "\n",
    "def process_frame(frame):\n",
    "#     print(\"frame shape: \", frame.shape)\n",
    "    resized_frame = tf.image.resize(frame, [224, 224], preserve_aspect_ratio=False)\n",
    "#     print(\"rsized1 shape: \", resized_frame.shape)\n",
    "    resized_frame = np.expand_dims(resized_frame, axis=0)\n",
    "#     print(\"rsized shape: \", resized_frame.shape)\n",
    "    interpreter.set_tensor(input_details[0]['index'], resized_frame)\n",
    "    interpreter.invoke()\n",
    "    output_data_0 = interpreter.get_tensor(output_details[0]['index'])\n",
    "    output_data_1 = interpreter.get_tensor(output_details[1]['index'])\n",
    "    output_data_2 = interpreter.get_tensor(output_details[2]['index'])\n",
    "    output_data_3 = interpreter.get_tensor(output_details[3]['index'])\n",
    "    return output_data_0, output_data_1, output_data_2, output_data_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-cross",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "print(input_shape)\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "racial-bhutan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'input_1',\n",
       " 'index': 0,\n",
       " 'shape': array([  1, 224, 224,   3]),\n",
       " 'shape_signature': array([  1, 224, 224,   3]),\n",
       " 'dtype': numpy.float32,\n",
       " 'quantization': (0.0, 0),\n",
       " 'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "  'zero_points': array([], dtype=int32),\n",
       "  'quantized_dimension': 0},\n",
       " 'sparsity_parameters': {}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_details[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-repository",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "interested-general",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.25430682, 0.40746945, 0.16861366],\n",
       "         [0.29629025, 0.4192725 , 0.01039161],\n",
       "         [0.9035795 , 0.14442316, 0.31675768],\n",
       "         ...,\n",
       "         [0.6228682 , 0.5205476 , 0.8174807 ],\n",
       "         [0.69619864, 0.95410913, 0.6030253 ],\n",
       "         [0.33573774, 0.42758608, 0.6578484 ]],\n",
       "\n",
       "        [[0.16462192, 0.3482242 , 0.9607842 ],\n",
       "         [0.6842862 , 0.9031328 , 0.18337312],\n",
       "         [0.85681653, 0.83401006, 0.8285552 ],\n",
       "         ...,\n",
       "         [0.93545836, 0.53672487, 0.28406367],\n",
       "         [0.21627063, 0.43438244, 0.6623999 ],\n",
       "         [0.6688025 , 0.74100274, 0.67211455]],\n",
       "\n",
       "        [[0.9767639 , 0.3705547 , 0.03942221],\n",
       "         [0.43846482, 0.6986182 , 0.67793685],\n",
       "         [0.05185306, 0.47779995, 0.9008208 ],\n",
       "         ...,\n",
       "         [0.90953976, 0.75774944, 0.3276761 ],\n",
       "         [0.54370075, 0.07237178, 0.26100832],\n",
       "         [0.32656583, 0.67829823, 0.36056882]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.01348164, 0.23558775, 0.72278917],\n",
       "         [0.34436166, 0.87609345, 0.02033561],\n",
       "         [0.673425  , 0.9490777 , 0.45841658],\n",
       "         ...,\n",
       "         [0.95878947, 0.01133014, 0.02386601],\n",
       "         [0.9712    , 0.48001716, 0.15891589],\n",
       "         [0.8840235 , 0.40065062, 0.16819045]],\n",
       "\n",
       "        [[0.85436743, 0.64912564, 0.6660269 ],\n",
       "         [0.65285677, 0.77279186, 0.9366803 ],\n",
       "         [0.33634037, 0.5291203 , 0.41021731],\n",
       "         ...,\n",
       "         [0.9777425 , 0.386715  , 0.845578  ],\n",
       "         [0.03864741, 0.20670956, 0.06333794],\n",
       "         [0.79190296, 0.41375843, 0.01629195]],\n",
       "\n",
       "        [[0.9464794 , 0.48045188, 0.0279701 ],\n",
       "         [0.8050031 , 0.96604973, 0.62776744],\n",
       "         [0.53163487, 0.90462923, 0.46688184],\n",
       "         ...,\n",
       "         [0.8900101 , 0.5437039 , 0.5301959 ],\n",
       "         [0.6741813 , 0.02043759, 0.94462985],\n",
       "         [0.83017087, 0.17208841, 0.23645662]]]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "defined-chinese",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.keras.layers' has no attribute 'Resizing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-f55455d3dc75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResizing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.keras.layers' has no attribute 'Resizing'"
     ]
    }
   ],
   "source": [
    "resizer = tf.keras.layers.Resizing(224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "numerous-completion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1, 224, 224,   3])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "collect-interference",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-engineering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-defense",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
